# disable default TargetDown rule, implement own that allows for optional scrape targets
defaultRules:
  disabled:
    TargetDown: true

additionalPrometheusRulesMap:
  default-override:
    groups:
      - name: override
        rules:
          - alert: "TargetDown"
            for: "10m"
            expr: '100 * (count by (cluster, job, namespace, service) (up{optional!="true"} == 0) / count by (cluster, job, namespace, service) (up{optional!="true"})) > 10'
            labels:
              severity: warning
            annotations:
              summary: "One or more targets are unreachable."
              description: '{{ printf "%.4g" $value }}% of the {{ $labels.job }}/{{ $labels.service }} targets in {{ $labels.namespace }} namespace are down.'

  pve-cluster-rules:
    groups:
      - name: systemd
        rules:
          - alert: "systemd service failed"
            for: "1m"
            expr: 'systemd_unit_state{state="failed"} == 1'
            labels:
              severity: critical
            annotations:
              summary: "Systemd service {{ $labels.name }} in stack {{ $labels.stack }} failed."
              description: "Instance {{ $labels.instance }} systemd service {{ $labels.name }} entered failed state."
              
      - name: ceph
        rules:
          - alert: "ceph device class near full"
            expr: "ceph_cluster_by_class_total_used_bytes / ceph_cluster_by_class_total_bytes > 0.9"
            for: "30s"
            labels:
              severity: "critical"
            annotations:
              summary: "Device class {{ $labels.device_class }} near full."
              description: "Device class {{ $labels.device_class }} is at {{ $value }} percent used."

          - alert: "ceph unhealthy"
            expr: "ceph_health_status == 1"
            for: "30s"
            labels:
              severity: "warning"
            annotations:
              summary: "Ceph is unhealthy."
              description: "Ceph is unhealthy."

          - alert: "ceph critical"
            expr: "ceph_health_status == 2"
            for: "30s"
            labels:
              severity: "critical"
            annotations:
              summary: "Ceph is in error state!"
              description: "Ceph in error state!"

          - alert: "ceph health detail warning"
            expr: "ceph_health_detail != 0"
            for: "30s"
            labels:
              severity: "warning"
            annotations:
              summary: "Ceph health warning."
              description: "Ceph health metric {{ $labels.name }} is in warning state."

      - name: pve-node
        rules:
          - alert: "ram usage critical"
            for: "30s"
            expr: 'node_memory_MemAvailable_bytes{job="pve-node"} / node_memory_MemTotal_bytes < 0.05'
            labels:
              severity: "critical"
            annotations:
              summary: "Ram usage for {{ $labels.host }} is critical."
              description: "Only {{ $value }} percent ram are free for host {{ $labels.host }}."

          - alert: "cpu usage critical"
            expr: 'avg by(instance) (rate(node_cpu_seconds_total{job="pve-node", mode="idle"}[1m])) < 0.05'
            for: "30m"
            labels:
              severity: "critical"
            annotations:
              summary: "CPU usage for {{ $labels.host }} is critical."
              description: "Only {{ $value }} percent cpu are unused for host {{ $labels.host }}."

      - name: haproxy
        rules:
          - alert: "haproxy all backends down"
            for: "1m"
            expr: 'haproxy_backend_active_servers == 0'
            labels:
              severity: "critical"
            annotations:
              summary: "All haproxy backends for proxy {{ $labels.proxy }} are down."
              description: "Haproxy {{  $labels.instance }} reported all backends down for proxy {{ $labels.proxy }}."